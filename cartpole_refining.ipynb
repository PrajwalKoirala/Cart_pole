{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "new_state = env.reset()\n",
    "done = False\n",
    "discount = 0.97\n",
    "epsilon = 1\n",
    "actions = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "W1 = tf.get_variable(\"W1\", [2,4], initializer = tf.random_normal_initializer(stddev = 1), dtype=tf.float64)\n",
    "New_state = tf.placeholder(tf.float64, shape = (4,1))\n",
    "Q_s = tf.matmul(W1, New_state)\n",
    "Action = tf.math.argmax(Q_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 199\n",
      "sigma: 7.346839692639297e-42\n",
      "total current reward: 500.0\n",
      "best reward: 500.0\n",
      "Weight: \n",
      "[[ 1.57586822 -0.03353617 -2.5560784  -1.45712782]\n",
      " [ 1.4654027   0.00380211  0.57314592  0.7595106 ]]\n"
     ]
    }
   ],
   "source": [
    "Episodes = 200\n",
    "sigma =  0.01\n",
    "last_W1 = sess.run(W1)\n",
    "best_rewards = -np.Inf\n",
    "for episode in range(Episodes):\n",
    "    new_state = env.reset()\n",
    "    rewards_in_this_episode = 0\n",
    "    done = False\n",
    "    show = True if episode%10==0 else False\n",
    "    sess.run(W1.assign_add( tf.random.normal([2,4], stddev = sigma, dtype = tf.float64)))\n",
    "    while not done:\n",
    "        action  = sess.run(Action, feed_dict = {New_state:new_state.reshape((4,1))})\n",
    "        new_state, reward, done, _ = env.step(action[0])\n",
    "        rewards_in_this_episode += reward\n",
    "        if show:\n",
    "            env.render()\n",
    "    if rewards_in_this_episode >= best_rewards:\n",
    "        last_W1 = sess.run(W1)\n",
    "        best_rewards = rewards_in_this_episode\n",
    "        sigma = sigma/2\n",
    "    else:\n",
    "        sess.run(W1.assign(last_W1))\n",
    "        sigma = sigma*2\n",
    "    print(\"episode: \" + str(episode))\n",
    "    print(\"sigma: \" + str(sigma))\n",
    "    print(\"total current reward: \" + str(rewards_in_this_episode))\n",
    "    print(\"best reward: \" + str(best_rewards))\n",
    "    print(\"Weight: \")\n",
    "    print(sess.run(W1))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "        \n",
    "env.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
